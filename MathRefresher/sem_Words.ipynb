{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/superkisa/MaGaML/blob/main/MathRefresher/sem_Words.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAmUD1eZHryf"
      },
      "source": [
        "# **Word vectors**\n",
        "\n",
        "\n",
        "In the previous exercise we observed that colors that we think of as similar are 'closer' to each other in RGB vector space. Is it possible to create a vector space for all English words that has this same 'closer in space is closer in meaning' property?\n",
        "\n",
        "The answer is yes! Luckily, you don't need to create those vectors from scratch. Many researchers have made downloadable databases of pre-trained vectors. One such project is [Stanford's Global Vectors for Word Representation (GloVe)](https://nlp.stanford.edu/projects/glove/). \n",
        "\n",
        "These $300$-dimensional vectors are included with $\\texttt{spaCy}$, and they're the vectors we'll be using in this exercise.\n",
        "\n",
        "![cosine similarity: picture](https://d33wubrfki0l68.cloudfront.net/d2742976a92aa4d6c39f19c747ec5f56ed1cec30/3803f/images/guide-to-word-vectors-with-gensim-and-keras_files/word2vec-king-queen-vectors.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymHr8XZIHsML",
        "outputId": "5a89f897-7fd1-4049-8fbc-f5da1cdf8bb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# The following will download the language model.\n",
        "# Resart the runtime (Runtime -> Restart runtime) after running this cell\n",
        "# (and don't run it for the second time).\n",
        "!python -m spacy download en_core_web_lg"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-lg==3.4.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.4.0/en_core_web_lg-3.4.0-py3-none-any.whl (587.7 MB)\n",
            "\u001b[K     |████████████████████████████▉   | 530.2 MB 4.1 kB/s eta 3:54:01\n",
            "\u001b[31mERROR: Exception:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/base_command.py\", line 180, in _main\n",
            "    status = self.run(options, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/req_command.py\", line 199, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/commands/install.py\", line 319, in run\n",
            "    reqs, check_supported_wheels=not options.target_dir\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 104, in resolve\n",
            "    req, requested_extras=()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 434, in make_requirement_from_install_req\n",
            "    version=None,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 205, in _make_candidate_from_link\n",
            "    version=version,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 312, in __init__\n",
            "    version=version,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 151, in __init__\n",
            "    self.dist = self._prepare()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 234, in _prepare\n",
            "    dist = self._prepare_distribution()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 318, in _prepare_distribution\n",
            "    self._ireq, parallel_builds=True\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/operations/prepare.py\", line 508, in prepare_linked_requirement\n",
            "    return self._prepare_linked_requirement(req, parallel_builds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/operations/prepare.py\", line 571, in _prepare_linked_requirement\n",
            "    req, self.req_tracker, self.finder, self.build_isolation,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/operations/prepare.py\", line 61, in _get_prepared_distribution\n",
            "    return abstract_dist.get_pkg_resources_distribution()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/distributions/wheel.py\", line 27, in get_pkg_resources_distribution\n",
            "    with ZipFile(self.req.local_file_path, allowZip64=True) as z:\n",
            "  File \"/usr/lib/python3.7/zipfile.py\", line 1258, in __init__\n",
            "    self._RealGetContents()\n",
            "  File \"/usr/lib/python3.7/zipfile.py\", line 1325, in _RealGetContents\n",
            "    raise BadZipFile(\"File is not a zip file\")\n",
            "zipfile.BadZipFile: File is not a zip file\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pb7yqHuGJ6e5"
      },
      "source": [
        "Let's load the model now:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-8rsSkSBU8C"
      },
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load('en_core_web_lg')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNf5FAkm3Ljj"
      },
      "source": [
        "## **Word vectors: the first glance**\n",
        "\n",
        "You can see the vector of any word in $\\texttt{spaCy}$' s vocabulary using the $\\texttt{vector}$ attribute:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vx-IzWxQAgNN",
        "outputId": "cd349cb5-3b78-4be4-9f94-1dfe27756f00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# A 300-dimensional vector\n",
        "len(nlp('dog').vector)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8UP3QrxKZPG",
        "outputId": "2b09b573-9708-464a-a467-14b6af3c0f94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nlp('dog').vector"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.2330e+00,  4.2963e+00, -7.9738e+00, -1.0121e+01,  1.8207e+00,\n",
              "        1.4098e+00, -4.5180e+00, -5.2261e+00, -2.9157e-01,  9.5234e-01,\n",
              "        6.9880e+00,  5.0637e+00, -5.5726e-03,  3.3395e+00,  6.4596e+00,\n",
              "       -6.3742e+00,  3.9045e-02, -3.9855e+00,  1.2085e+00, -1.3186e+00,\n",
              "       -4.8886e+00,  3.7066e+00, -2.8281e+00, -3.5447e+00,  7.6888e-01,\n",
              "        1.5016e+00, -4.3632e+00,  8.6480e+00, -5.9286e+00, -1.3055e+00,\n",
              "        8.3870e-01,  9.0137e-01, -1.7843e+00, -1.0148e+00,  2.7300e+00,\n",
              "       -6.9039e+00,  8.0413e-01,  7.4880e+00,  6.1078e+00, -4.2130e+00,\n",
              "       -1.5384e-01, -5.4995e+00,  1.0896e+01,  3.9278e+00, -1.3601e-01,\n",
              "        7.7732e-02,  3.2218e+00, -5.8777e+00,  6.1359e-01, -2.4287e+00,\n",
              "        6.2820e+00,  1.3461e+01,  4.3236e+00,  2.4266e+00, -2.6512e+00,\n",
              "        1.1577e+00,  5.0848e+00, -1.7058e+00,  3.3824e+00,  3.2850e+00,\n",
              "        1.0969e+00, -8.3711e+00, -1.5554e+00,  2.0296e+00, -2.6796e+00,\n",
              "       -6.9195e+00, -2.3386e+00, -1.9916e+00, -3.0450e+00,  2.4890e+00,\n",
              "        7.3247e+00,  1.3364e+00,  2.3828e-01,  8.4388e-02,  3.1480e+00,\n",
              "       -1.1128e+00, -3.5598e+00, -1.2115e-01, -2.0357e+00, -3.2731e+00,\n",
              "       -7.7205e+00,  4.0948e+00, -2.0732e+00,  2.0833e+00, -2.2803e+00,\n",
              "       -4.9850e+00,  9.7667e+00,  6.1779e+00, -1.0352e+01, -2.2268e+00,\n",
              "        2.5765e+00, -5.7440e+00,  5.5564e+00, -5.2735e+00,  3.0004e+00,\n",
              "       -4.2512e+00, -1.5682e+00,  2.2698e+00,  1.0491e+00, -9.0486e+00,\n",
              "        4.2936e+00,  1.8709e+00,  5.1985e+00, -1.3153e+00,  6.5224e+00,\n",
              "        4.0113e-01, -1.2583e+01,  3.6534e+00, -2.0961e+00,  1.0022e+00,\n",
              "       -1.7873e+00, -4.2555e+00,  7.7471e+00,  1.0173e+00,  3.1626e+00,\n",
              "        2.3558e+00,  3.3589e-01, -4.4178e+00,  5.0584e+00, -2.4118e+00,\n",
              "       -2.7445e+00,  3.4170e+00, -1.1574e+01, -2.6568e+00, -3.6933e+00,\n",
              "       -2.0398e+00,  5.0976e+00,  6.5249e+00,  3.3573e+00,  9.5334e-01,\n",
              "       -9.4430e-01, -9.4395e+00,  2.7867e+00, -1.7549e+00,  1.7287e+00,\n",
              "        3.4942e+00, -1.6883e+00, -3.5771e+00, -1.9013e+00,  2.2239e+00,\n",
              "       -5.4335e+00, -6.5724e+00, -6.7228e-01, -1.9748e+00, -3.1080e+00,\n",
              "       -1.8570e+00,  9.9496e-01,  8.9135e-01, -4.4254e+00,  3.3125e-01,\n",
              "        5.8815e+00,  1.9384e+00,  5.7294e-01, -2.8830e+00,  3.8087e+00,\n",
              "       -1.3095e+00,  5.9208e+00,  3.3620e+00,  3.3571e+00, -3.8807e-01,\n",
              "        9.0022e-01, -5.5742e+00, -4.2939e+00,  1.4992e+00, -4.7080e+00,\n",
              "       -2.9402e+00, -1.2259e+00,  3.0980e-01,  1.8858e+00, -1.9867e+00,\n",
              "       -2.3554e-01, -5.4535e-01, -2.1387e-01,  2.4797e+00,  5.9710e+00,\n",
              "       -7.1249e+00,  1.6257e+00, -1.5241e+00,  7.5974e-01,  1.4312e+00,\n",
              "        2.3641e+00, -3.5566e+00,  9.2066e-01,  4.4934e-01, -1.3233e+00,\n",
              "        3.1733e+00, -4.7059e+00, -1.2090e+01, -3.9241e-01, -6.8457e-01,\n",
              "       -3.6789e+00,  6.6279e+00, -2.9937e+00, -3.8361e+00,  1.3868e+00,\n",
              "       -4.9002e+00, -2.4299e+00,  6.4312e+00,  2.5056e+00, -4.5080e+00,\n",
              "       -5.1278e+00, -1.5585e+00, -3.0226e+00, -8.6811e-01, -1.1538e+00,\n",
              "       -1.0022e+00, -9.1651e-01, -4.7810e-01, -1.6084e+00, -2.7307e+00,\n",
              "        3.7080e+00,  7.7423e-01, -1.1085e+00, -6.8755e-01, -8.2901e+00,\n",
              "        3.2405e+00, -1.6108e-01, -6.2837e-01, -5.5960e+00, -4.4865e+00,\n",
              "        4.0115e-01, -3.7063e+00, -2.1704e+00,  4.0789e+00, -1.7973e+00,\n",
              "        8.9538e+00,  8.9421e-01, -4.8128e+00,  4.5367e+00, -3.2579e-01,\n",
              "       -5.2344e+00, -3.9766e+00, -2.1979e+00,  3.5699e+00,  1.4982e+00,\n",
              "        6.0972e+00, -1.9704e+00,  4.6522e+00, -3.7734e-01,  3.9101e-02,\n",
              "        2.5361e+00, -1.8096e+00,  8.7035e+00, -8.6372e+00, -3.5257e+00,\n",
              "        3.1034e+00,  3.2635e+00,  4.5437e+00, -5.7290e+00, -2.9141e-01,\n",
              "       -2.0011e+00,  8.5328e+00, -4.5064e+00, -4.8276e+00, -1.1786e+01,\n",
              "        3.5607e-01, -5.7115e+00,  6.3122e+00, -3.6650e+00,  3.3597e-01,\n",
              "        2.5017e+00, -3.5025e+00, -3.7891e+00, -3.1343e+00, -1.4429e+00,\n",
              "       -6.9119e+00, -2.6114e+00, -5.9757e-01,  3.7847e-01,  6.3187e+00,\n",
              "        2.8965e+00, -2.5397e+00,  1.8022e+00,  3.5486e+00,  4.4721e+00,\n",
              "       -4.8481e+00, -3.6252e+00,  4.0969e+00, -2.0081e+00, -2.0122e-01,\n",
              "        2.5244e+00, -6.8817e-01,  6.7184e-01, -7.0466e+00,  1.6641e+00,\n",
              "       -2.2308e+00, -3.8960e+00,  6.1320e+00, -8.0335e+00, -1.7130e+00,\n",
              "        2.5688e+00, -5.2547e+00,  6.9845e+00,  2.7835e-01, -6.4554e+00,\n",
              "       -2.1327e+00, -5.6515e+00,  1.1174e+01, -8.0568e+00,  5.7985e+00],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHWCqKcl55TY"
      },
      "source": [
        "## **Cosine similarity**\n",
        "\n",
        "**Cosine similarity** is a common way of assessing similarity between words in NLP. It is essentially defined as the cosine of the angle between the vectors representing the words of interest.\n",
        "\n",
        "Recall that the angle $\\phi$ between two non-zero vectors $u$ and $v$ can be computed as follows:\n",
        "\n",
        "$cos(\\phi) = \\frac{(u,v)}{||u||\\cdot||v||}$\n",
        "\n",
        "![](https://miro.medium.com/max/1394/1*_Bf9goaALQrS_0XkBozEiQ.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoi6FvPgMWid"
      },
      "source": [
        "Define a function computing cosine similarity between two vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpJS01dmvGbe"
      },
      "source": [
        "import numpy as np\n",
        "from math import sqrt\n",
        "\n",
        "def cosine(v1, v2):\n",
        "  # Your code here\n",
        "  return np.sum(v1*v2)/(sqrt(np.sum(v1*v1))*sqrt(np.sum(v2*v2)))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEwtAXJRMc-s"
      },
      "source": [
        "Test your function by computing similarities of some random pairs of words, e.g. $dog$ and $puppy$ vs. $dog$ and $kitten$. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RBooDbGvYOG",
        "outputId": "6e4ffdb7-a298-4332-c09e-40ed98b519a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Your code here\n",
        "print(cosine(nlp('dog').vector, nlp('puppy').vector))\n",
        "print(cosine(nlp('dog').vector, nlp('kitten').vector))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8107667523600081\n",
            "0.6515031235181183\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgHDwfx8Mu66"
      },
      "source": [
        "## **Loading the text**\n",
        "\n",
        "Let's load the full text of *Alice in Wonderland*. It will serve us as a corpus of English words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "am8NoIl2zMXi"
      },
      "source": [
        "import requests\n",
        "\n",
        "# Alice in Wonderland\n",
        "response = requests.get('https://www.gutenberg.org/files/11/11-0.txt')\n",
        "\n",
        "# If you prefer Dracula, load this instead:\n",
        "#response = requests.get('https://www.gutenberg.org/cache/epub/345/pg345.txt')\n",
        "\n",
        "# Extracting separate words from the text\n",
        "doc = nlp(response.text)\n",
        "tokens = list(set([w.text for w in doc if w.is_alpha]))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAwABf4nNNR3"
      },
      "source": [
        "Check out the content of $\\texttt{tokens}$ now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4B4FRR6NRzx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae0a8958-b18b-4400-d5be-f6239e1db255"
      },
      "source": [
        "tokens"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['TRADEMARK',\n",
              " 'verse',\n",
              " 'favoured',\n",
              " 'Section',\n",
              " 'twenty',\n",
              " 'seaside',\n",
              " 'pleasanter',\n",
              " 'neck',\n",
              " 'It',\n",
              " 'same',\n",
              " 'pigeon',\n",
              " 'grunt',\n",
              " 'Take',\n",
              " 'clamour',\n",
              " 'hollow',\n",
              " 'afore',\n",
              " 'patted',\n",
              " 'breathe',\n",
              " 'Ground',\n",
              " 'foolish',\n",
              " 'better',\n",
              " 'We',\n",
              " 'curls',\n",
              " 'Mercia',\n",
              " 'paint',\n",
              " 'brave',\n",
              " 'clear',\n",
              " 'lifted',\n",
              " 'Paris',\n",
              " 'Why',\n",
              " 'else',\n",
              " 'States',\n",
              " 'Her',\n",
              " 'maintaining',\n",
              " 'King',\n",
              " 'zigzag',\n",
              " 'licking',\n",
              " 'chimney',\n",
              " 'files',\n",
              " 'pretending',\n",
              " 'round',\n",
              " 'goose',\n",
              " 'kissed',\n",
              " 'distribute',\n",
              " 'trees',\n",
              " 'Heads',\n",
              " 'daughter',\n",
              " 'denying',\n",
              " 'FITNESS',\n",
              " 'miles',\n",
              " 'dry',\n",
              " 'remembered',\n",
              " 'think',\n",
              " 'bent',\n",
              " 'choke',\n",
              " 'plate',\n",
              " 'quietly',\n",
              " 'centre',\n",
              " 'feather',\n",
              " 'comfortable',\n",
              " 'DISTRIBUTE',\n",
              " 'proprietary',\n",
              " 'pebbles',\n",
              " 'figure',\n",
              " 'lobster',\n",
              " 'traps',\n",
              " 'secret',\n",
              " 'commercial',\n",
              " 'grow',\n",
              " 'financial',\n",
              " 'copied',\n",
              " 'listen',\n",
              " 'do',\n",
              " 'succeeded',\n",
              " 'user',\n",
              " 'LIABLE',\n",
              " 'INCLUDING',\n",
              " 'country',\n",
              " 'tight',\n",
              " 'shrill',\n",
              " 'attending',\n",
              " 'Before',\n",
              " 'Rome',\n",
              " 'idea',\n",
              " 'becoming',\n",
              " 'sneezed',\n",
              " 'these',\n",
              " 'paper',\n",
              " 'ago',\n",
              " 'belt',\n",
              " 'Imagine',\n",
              " 'shouted',\n",
              " 'machine',\n",
              " 'coaxing',\n",
              " 'downloading',\n",
              " 'awfully',\n",
              " 'drink',\n",
              " 'despair',\n",
              " 'defect',\n",
              " 'pattering',\n",
              " 'Everybody',\n",
              " 'pulling',\n",
              " 'trials',\n",
              " 'shaped',\n",
              " 'solid',\n",
              " 'cautiously',\n",
              " 'PGLAF',\n",
              " 'By',\n",
              " 'sadly',\n",
              " 'horse',\n",
              " 'sharks',\n",
              " 'between',\n",
              " 'years',\n",
              " 'addresses',\n",
              " 'melancholy',\n",
              " 'say',\n",
              " 'rumbling',\n",
              " 'upset',\n",
              " 'riddles',\n",
              " 'dark',\n",
              " 'roughly',\n",
              " 'high',\n",
              " 'delightful',\n",
              " 'Allow',\n",
              " 'tunnel',\n",
              " 'untwist',\n",
              " 'conclusion',\n",
              " 'glanced',\n",
              " 'desperate',\n",
              " 'fury',\n",
              " 'keeping',\n",
              " 'named',\n",
              " 'marked',\n",
              " 'strings',\n",
              " 'patience',\n",
              " 'beast',\n",
              " 'marched',\n",
              " 'thoughts',\n",
              " 'swimming',\n",
              " 'stand',\n",
              " 'Despite',\n",
              " 'solicitation',\n",
              " 'bursting',\n",
              " 'seemed',\n",
              " 'without',\n",
              " 'pretexts',\n",
              " 'and',\n",
              " 'aloud',\n",
              " 'nibbling',\n",
              " 'manner',\n",
              " 'pass',\n",
              " 'towards',\n",
              " 'uneasily',\n",
              " 'lieu',\n",
              " 'hiss',\n",
              " 'lovely',\n",
              " 'works',\n",
              " 'only',\n",
              " 'curtseying',\n",
              " 'ground',\n",
              " 'girl',\n",
              " 'easily',\n",
              " 'created',\n",
              " 'formats',\n",
              " 'directly',\n",
              " 'largest',\n",
              " 'pine',\n",
              " 'their',\n",
              " 'thistle',\n",
              " 'state',\n",
              " 'beg',\n",
              " 'undertone',\n",
              " 'gratefully',\n",
              " 'returned',\n",
              " 'imagine',\n",
              " 'itself',\n",
              " 'On',\n",
              " 'thick',\n",
              " 'Trims',\n",
              " 'pence',\n",
              " 'electronically',\n",
              " 'readily',\n",
              " 'court',\n",
              " 'want',\n",
              " 'fixed',\n",
              " 'Contents',\n",
              " 'pattern',\n",
              " 'sort',\n",
              " 'With',\n",
              " 'scolded',\n",
              " 'grew',\n",
              " 'owed',\n",
              " 'donors',\n",
              " 'knows',\n",
              " 'Distraction',\n",
              " 'wearily',\n",
              " 'distribution',\n",
              " 'inwards',\n",
              " 'crimson',\n",
              " 'fumbled',\n",
              " 'vague',\n",
              " 'executions',\n",
              " 'common',\n",
              " 'owns',\n",
              " 'permanent',\n",
              " 'quiver',\n",
              " 'twentieth',\n",
              " 'useful',\n",
              " 'impatiently',\n",
              " 'wandered',\n",
              " 'Do',\n",
              " 'goes',\n",
              " 'English',\n",
              " 'set',\n",
              " 'Grief',\n",
              " 'tray',\n",
              " 'caterpillar',\n",
              " 'organized',\n",
              " 'Mystery',\n",
              " 'plainly',\n",
              " 'sharply',\n",
              " 'presents',\n",
              " 'whole',\n",
              " 'outside',\n",
              " 'raised',\n",
              " 'skimming',\n",
              " 'newspapers',\n",
              " 'last',\n",
              " 'swallowed',\n",
              " 'confirmation',\n",
              " 'every',\n",
              " 'Improve',\n",
              " 'happening',\n",
              " 'toffee',\n",
              " 'hedgehog',\n",
              " 'Those',\n",
              " 'consented',\n",
              " 'mischief',\n",
              " 'tremble',\n",
              " 'anxious',\n",
              " 'Ann',\n",
              " 'fidgeted',\n",
              " 'occasionally',\n",
              " 'Hardly',\n",
              " 'sigh',\n",
              " 'treat',\n",
              " 'remember',\n",
              " 'relieved',\n",
              " 'reasons',\n",
              " 'oh',\n",
              " 'mad',\n",
              " 'web',\n",
              " 'leaders',\n",
              " 'faint',\n",
              " 'inclined',\n",
              " 'distributed',\n",
              " 'usurpation',\n",
              " 'twist',\n",
              " 'height',\n",
              " 'fine',\n",
              " 'vinegar',\n",
              " 'bound',\n",
              " 'children',\n",
              " 'Canary',\n",
              " 'calculate',\n",
              " 'Next',\n",
              " 'narrow',\n",
              " 'Nearly',\n",
              " 'solemnly',\n",
              " 'Miss',\n",
              " 'stoop',\n",
              " 'ferrets',\n",
              " 'treading',\n",
              " 'Lobster',\n",
              " 'rich',\n",
              " 'laughed',\n",
              " 'velvet',\n",
              " 'hands',\n",
              " 'ordered',\n",
              " 'dreamed',\n",
              " 'when',\n",
              " 'fee',\n",
              " 'pleaded',\n",
              " 'carrier',\n",
              " 'constant',\n",
              " 'jurymen',\n",
              " 'License',\n",
              " 'quiet',\n",
              " 'old',\n",
              " 'damages',\n",
              " 'uncomfortably',\n",
              " 'PARAGRAPH',\n",
              " 'trembling',\n",
              " 'cutting',\n",
              " 'waistcoat',\n",
              " 'visit',\n",
              " 'rustling',\n",
              " 'whiskers',\n",
              " 'hearth',\n",
              " 'to',\n",
              " 'cleared',\n",
              " 'spectacles',\n",
              " 'sign',\n",
              " 'mostly',\n",
              " 'pounds',\n",
              " 'seems',\n",
              " 'Illustration',\n",
              " 'begun',\n",
              " 'Ugh',\n",
              " 'Never',\n",
              " 'b',\n",
              " 'William',\n",
              " 'much',\n",
              " 'age',\n",
              " 'whispers',\n",
              " 'Little',\n",
              " 'Race',\n",
              " 'side',\n",
              " 'startled',\n",
              " 'Elsie',\n",
              " 'ADVENTURES',\n",
              " 'ought',\n",
              " 'beginning',\n",
              " 'redistributing',\n",
              " 'any',\n",
              " 'hastily',\n",
              " 'sob',\n",
              " 'nobody',\n",
              " 'cool',\n",
              " 'widest',\n",
              " 'Pool',\n",
              " 'hand',\n",
              " 'curled',\n",
              " 'invented',\n",
              " 'ye',\n",
              " 'hearts',\n",
              " 'naturedly',\n",
              " 'snout',\n",
              " 'critical',\n",
              " 'murder',\n",
              " 'ten',\n",
              " 'additional',\n",
              " 'shade',\n",
              " 'eager',\n",
              " 'so',\n",
              " 'ear',\n",
              " 'ridges',\n",
              " 'arches',\n",
              " 'star',\n",
              " 'living',\n",
              " 'containing',\n",
              " 'brushing',\n",
              " 'affair',\n",
              " 'tucked',\n",
              " 'beautify',\n",
              " 'hundreds',\n",
              " 'detach',\n",
              " 'baked',\n",
              " 'tossing',\n",
              " 'flew',\n",
              " 'remain',\n",
              " 'hurry',\n",
              " 'asking',\n",
              " 'complying',\n",
              " 'Hare',\n",
              " 'agreement',\n",
              " 'exactly',\n",
              " 'been',\n",
              " 'Fender',\n",
              " 'Shall',\n",
              " 'determine',\n",
              " 'child',\n",
              " 'is',\n",
              " 'smile',\n",
              " 'Laughing',\n",
              " 'City',\n",
              " 'USE',\n",
              " 'wonderful',\n",
              " 'show',\n",
              " 'twinkled',\n",
              " 'less',\n",
              " 'hatters',\n",
              " 'widespread',\n",
              " 'still',\n",
              " 'hung',\n",
              " 'powdered',\n",
              " 'possibly',\n",
              " 'likely',\n",
              " 'tarts',\n",
              " 'pressing',\n",
              " 'upsetting',\n",
              " 'alive',\n",
              " 'course',\n",
              " 'live',\n",
              " 'head',\n",
              " 'suit',\n",
              " 'PUNITIVE',\n",
              " 'box',\n",
              " 'pretend',\n",
              " 'Two',\n",
              " 'laid',\n",
              " 'lose',\n",
              " 'impossible',\n",
              " 'hedges',\n",
              " 'providing',\n",
              " 'shiver',\n",
              " 'absence',\n",
              " 'Will',\n",
              " 'quite',\n",
              " 'your',\n",
              " 'beautifully',\n",
              " 'NOT',\n",
              " 'juror',\n",
              " 'dropped',\n",
              " 'rise',\n",
              " 'interrupt',\n",
              " 'touch',\n",
              " 'party',\n",
              " 'cherry',\n",
              " 'wander',\n",
              " 'white',\n",
              " 'cook',\n",
              " 'shock',\n",
              " 'fortunately',\n",
              " 'tree',\n",
              " 'terms',\n",
              " 'help',\n",
              " 'creatures',\n",
              " 'requirements',\n",
              " 'disk',\n",
              " 'really',\n",
              " 'Uglification',\n",
              " 'pot',\n",
              " 'appearance',\n",
              " 'globe',\n",
              " 'how',\n",
              " 'prohibition',\n",
              " 'whisper',\n",
              " 'speaking',\n",
              " 'PROJECT',\n",
              " 'driest',\n",
              " 'honour',\n",
              " 'master',\n",
              " 'effect',\n",
              " 'saucepan',\n",
              " 'drop',\n",
              " 'worth',\n",
              " 'footman',\n",
              " 'unwillingly',\n",
              " 'wags',\n",
              " 'bee',\n",
              " 'hoarse',\n",
              " 'crumbs',\n",
              " 'drive',\n",
              " 'familiarly',\n",
              " 'manage',\n",
              " 'located',\n",
              " 'jaw',\n",
              " 'appear',\n",
              " 'something',\n",
              " 'Full',\n",
              " 'opportunities',\n",
              " 'prize',\n",
              " 'commotion',\n",
              " 'knowledge',\n",
              " 'entangled',\n",
              " 'return',\n",
              " 'Last',\n",
              " 'various',\n",
              " 'morals',\n",
              " 'drunk',\n",
              " 'Ah',\n",
              " 'protect',\n",
              " 'proceed',\n",
              " 'chorus',\n",
              " 'bark',\n",
              " 'bone',\n",
              " 'passage',\n",
              " 'eats',\n",
              " 'merrily',\n",
              " 'WONDERLAND',\n",
              " 'dish',\n",
              " 'care',\n",
              " 'contain',\n",
              " 'taller',\n",
              " 'squeezed',\n",
              " 'property',\n",
              " 'wonder',\n",
              " 'having',\n",
              " 'ornamented',\n",
              " 'overcome',\n",
              " 'cried',\n",
              " 'retire',\n",
              " 'prisoner',\n",
              " 'elbow',\n",
              " 'available',\n",
              " 'pretty',\n",
              " 'uncomfortable',\n",
              " 'jury',\n",
              " 'support',\n",
              " 'stretching',\n",
              " 'jug',\n",
              " 'settle',\n",
              " 'aged',\n",
              " 'hid',\n",
              " 'WITH',\n",
              " 'meat',\n",
              " 'dreadful',\n",
              " 'top',\n",
              " 'begins',\n",
              " 'messages',\n",
              " 'pay',\n",
              " 'sizes',\n",
              " 'Soup',\n",
              " 'offer',\n",
              " 'PURPOSE',\n",
              " 'days',\n",
              " 'eyelids',\n",
              " 'So',\n",
              " 'At',\n",
              " 'furrow',\n",
              " 'words',\n",
              " 'whistling',\n",
              " 'hunting',\n",
              " 'paid',\n",
              " 'rats',\n",
              " 'does',\n",
              " 'lasted',\n",
              " 'instead',\n",
              " 'wept',\n",
              " 'left',\n",
              " 'happy',\n",
              " 'doubled',\n",
              " 'royalties',\n",
              " 'able',\n",
              " 'changes',\n",
              " 'invent',\n",
              " 'invitation',\n",
              " 'viewing',\n",
              " 'disclaim',\n",
              " 'purpose',\n",
              " 'none',\n",
              " 'called',\n",
              " 'derived',\n",
              " 'word',\n",
              " 'Edwin',\n",
              " 'large',\n",
              " 'SUCH',\n",
              " 'stupidest',\n",
              " 'Indeed',\n",
              " 'approach',\n",
              " 'true',\n",
              " 'circumstances',\n",
              " 'pictured',\n",
              " 'doth',\n",
              " 'appeared',\n",
              " 'crawled',\n",
              " 'mournful',\n",
              " 'changing',\n",
              " 'performances',\n",
              " 'cries',\n",
              " 'encoding',\n",
              " 'slipped',\n",
              " 'walk',\n",
              " 'bowing',\n",
              " 'loudly',\n",
              " 'killing',\n",
              " 'whether',\n",
              " 'told',\n",
              " 'those',\n",
              " 'editions',\n",
              " 'us',\n",
              " 'copyright',\n",
              " 'running',\n",
              " 'world',\n",
              " 'notice',\n",
              " 'cats',\n",
              " 'intellectual',\n",
              " 'search',\n",
              " 'cry',\n",
              " 'Pennyworth',\n",
              " 'fact',\n",
              " 'MERCHANTABILITY',\n",
              " 'Lewis',\n",
              " 'The',\n",
              " 'clock',\n",
              " 'burnt',\n",
              " 'Special',\n",
              " 'my',\n",
              " 'bough',\n",
              " 'Either',\n",
              " 'lower',\n",
              " 'because',\n",
              " 'Then',\n",
              " 'just',\n",
              " 'where',\n",
              " 'require',\n",
              " 'deeply',\n",
              " 'replied',\n",
              " 'butter',\n",
              " 'bird',\n",
              " 'excellent',\n",
              " 'yourself',\n",
              " 'escape',\n",
              " 'airs',\n",
              " 'trickling',\n",
              " 'frog',\n",
              " 'meet',\n",
              " 'taking',\n",
              " 'knocking',\n",
              " 'limited',\n",
              " 'Some',\n",
              " 'jaws',\n",
              " 'precious',\n",
              " 'understood',\n",
              " 'behind',\n",
              " 'cut',\n",
              " 'Adventures',\n",
              " 'skurried',\n",
              " 'buttercup',\n",
              " 'Seaography',\n",
              " 'POSSIBILITY',\n",
              " 'One',\n",
              " 'plan',\n",
              " 'right',\n",
              " 'all',\n",
              " 'next',\n",
              " 'garden',\n",
              " 'darkness',\n",
              " 'pleased',\n",
              " 'sounded',\n",
              " 'line',\n",
              " 'jogged',\n",
              " 'whatsoever',\n",
              " 'understand',\n",
              " 'entirely',\n",
              " 'Queens',\n",
              " 'frying',\n",
              " 'advise',\n",
              " 'lonely',\n",
              " 'lips',\n",
              " 'rightly',\n",
              " 'Sounds',\n",
              " 'toast',\n",
              " 'include',\n",
              " 'gay',\n",
              " 'burn',\n",
              " 'Owl',\n",
              " 'exclaimed',\n",
              " 'III',\n",
              " 'procession',\n",
              " 'lowing',\n",
              " 'Queen',\n",
              " 'closer',\n",
              " 'scream',\n",
              " 'loving',\n",
              " 'credit',\n",
              " 'followed',\n",
              " 'anyone',\n",
              " 'longer',\n",
              " 'waters',\n",
              " 'Tell',\n",
              " 'forehead',\n",
              " 'toss',\n",
              " 'DONATIONS',\n",
              " 'undo',\n",
              " 'renamed',\n",
              " 'restrictions',\n",
              " 'IX',\n",
              " 'downward',\n",
              " 'lobsters',\n",
              " 'obtain',\n",
              " 'Hearthrug',\n",
              " 'delighted',\n",
              " 'finds',\n",
              " 'apples',\n",
              " 'shoes',\n",
              " 'fanning',\n",
              " 'dreamy',\n",
              " 'feathers',\n",
              " 'furious',\n",
              " 'bye',\n",
              " 'frontispiece',\n",
              " 'nervous',\n",
              " 'if',\n",
              " 'His',\n",
              " 'binary',\n",
              " 'unless',\n",
              " 'fitted',\n",
              " 'sobbing',\n",
              " 'indemnify',\n",
              " 'crust',\n",
              " 'carrying',\n",
              " 'crab',\n",
              " 'indicate',\n",
              " 'warning',\n",
              " 'based',\n",
              " 'angrily',\n",
              " 'heart',\n",
              " 'Defects',\n",
              " 'red',\n",
              " 'person',\n",
              " 'theirs',\n",
              " 'getting',\n",
              " 'Professor',\n",
              " 'quarrelled',\n",
              " 'writing',\n",
              " 'physical',\n",
              " 'glad',\n",
              " 'About',\n",
              " 'tastes',\n",
              " 'pack',\n",
              " 'usually',\n",
              " 'ceiling',\n",
              " 'diligently',\n",
              " 'sharing',\n",
              " 'VIII',\n",
              " 'almost',\n",
              " 'hopeless',\n",
              " 'crash',\n",
              " 'felt',\n",
              " 'walked',\n",
              " 'Eaglet',\n",
              " 'No',\n",
              " 'settling',\n",
              " 'worried',\n",
              " 'lodging',\n",
              " 'fluttered',\n",
              " 'shorter',\n",
              " 'destroy',\n",
              " 'story',\n",
              " 'actually',\n",
              " 'Unless',\n",
              " 'medium',\n",
              " 'game',\n",
              " 'strength',\n",
              " 'breeze',\n",
              " 'deal',\n",
              " 'Like',\n",
              " 'tulip',\n",
              " 'burning',\n",
              " 'sitting',\n",
              " 'throwing',\n",
              " 'became',\n",
              " 'Mock',\n",
              " 'anxiously',\n",
              " 'Stop',\n",
              " 'Be',\n",
              " 'shower',\n",
              " 'thoroughly',\n",
              " 'pig',\n",
              " 'terrier',\n",
              " 'assembled',\n",
              " 'lefthand',\n",
              " 'choose',\n",
              " 'answer',\n",
              " 'dodged',\n",
              " 'solemn',\n",
              " 'generations',\n",
              " 'offended',\n",
              " 'the',\n",
              " 'bore',\n",
              " 'footsteps',\n",
              " 'pink',\n",
              " 'hearing',\n",
              " 'flying',\n",
              " 'leap',\n",
              " 'leaving',\n",
              " 'second',\n",
              " 'lady',\n",
              " 'calmly',\n",
              " 'bring',\n",
              " 'group',\n",
              " 'thing',\n",
              " 'ashamed',\n",
              " 'direction',\n",
              " 'patiently',\n",
              " 'voice',\n",
              " 'annoy',\n",
              " 'promoting',\n",
              " 'uneasy',\n",
              " 'DAMAGE',\n",
              " 'volunteer',\n",
              " 'texts',\n",
              " 'swim',\n",
              " 'boldly',\n",
              " 'puppy',\n",
              " 'see',\n",
              " 'hair',\n",
              " 'morsel',\n",
              " 'puzzled',\n",
              " 'Hearts',\n",
              " 'CONSEQUENTIAL',\n",
              " 'THE',\n",
              " 'prove',\n",
              " 'scratching',\n",
              " 'beasts',\n",
              " 'signify',\n",
              " 'doubtful',\n",
              " 'bread',\n",
              " 'possessed',\n",
              " 'boots',\n",
              " 'argue',\n",
              " 'pigs',\n",
              " 'Contact',\n",
              " 'CONTRACT',\n",
              " 'died',\n",
              " 'CHORUS',\n",
              " 'pause',\n",
              " 'whispered',\n",
              " 'quickly',\n",
              " 'chose',\n",
              " 'angry',\n",
              " 'beheaded',\n",
              " 'threw',\n",
              " 'believed',\n",
              " 'whereupon',\n",
              " 'legally',\n",
              " 'makes',\n",
              " 'cease',\n",
              " 'timid',\n",
              " 'addition',\n",
              " 'quick',\n",
              " 'could',\n",
              " 'Arthur',\n",
              " 'along',\n",
              " 'sorry',\n",
              " 'began',\n",
              " 'case',\n",
              " 'caused',\n",
              " 'mail',\n",
              " 's',\n",
              " 'particularly',\n",
              " 'happens',\n",
              " 'fall',\n",
              " 'annoyed',\n",
              " 'stuff',\n",
              " 'ordering',\n",
              " 'difficult',\n",
              " 'Run',\n",
              " 'OTHER',\n",
              " 'telling',\n",
              " 'muscular',\n",
              " 'unpleasant',\n",
              " 'call',\n",
              " 'subdued',\n",
              " 'different',\n",
              " 'duck',\n",
              " 'screamed',\n",
              " 'parchment',\n",
              " 'thirteen',\n",
              " 'important',\n",
              " 'concept',\n",
              " 'WILL',\n",
              " 'UT',\n",
              " 'certain',\n",
              " 'pet',\n",
              " 'given',\n",
              " 'FOUNDATION',\n",
              " 'What',\n",
              " 'lit',\n",
              " 'whiting',\n",
              " 'repeating',\n",
              " 'saucer',\n",
              " 'led',\n",
              " 'using',\n",
              " 'mouths',\n",
              " 'home',\n",
              " 'moderate',\n",
              " 'produce',\n",
              " 'hurrying',\n",
              " 'curious',\n",
              " 'govern',\n",
              " 'blown',\n",
              " 'Updated',\n",
              " 'blows',\n",
              " 'sulky',\n",
              " 'Classics',\n",
              " 'which',\n",
              " 'there',\n",
              " 'would',\n",
              " 'queer',\n",
              " 'fair',\n",
              " 'access',\n",
              " 'Now',\n",
              " 'steam',\n",
              " 'original',\n",
              " 'occur',\n",
              " 'parts',\n",
              " 'schoolroom',\n",
              " 'save',\n",
              " 'PLEASE',\n",
              " 'meeting',\n",
              " 'compliance',\n",
              " 'leave',\n",
              " 'guests',\n",
              " 'turtles',\n",
              " 'comply',\n",
              " 'lost',\n",
              " 'Most',\n",
              " 'thatched',\n",
              " 'fear',\n",
              " 'push',\n",
              " 'limitation',\n",
              " 'unenforceability',\n",
              " 'necessarily',\n",
              " 'Turn',\n",
              " 'provoking',\n",
              " 'fan',\n",
              " 'Quadrille',\n",
              " 'poor',\n",
              " 'continued',\n",
              " 'easy',\n",
              " 'declared',\n",
              " 'draggled',\n",
              " 'alas',\n",
              " 'upright',\n",
              " 'takes',\n",
              " 'should',\n",
              " 'hundred',\n",
              " 'moved',\n",
              " 'personal',\n",
              " 'broken',\n",
              " 'mallets',\n",
              " 'indignant',\n",
              " 'crouched',\n",
              " 'together',\n",
              " 'directed',\n",
              " 'crocodile',\n",
              " 'watch',\n",
              " 'Atheling',\n",
              " 'REMEDIES',\n",
              " 'minute',\n",
              " 'wants',\n",
              " 'faces',\n",
              " 'pointed',\n",
              " 'discover',\n",
              " 'roared',\n",
              " 'pinched',\n",
              " 'Luckily',\n",
              " 'result',\n",
              " 'KING',\n",
              " 'cardboard',\n",
              " 'feel',\n",
              " 'expecting',\n",
              " 'conversation',\n",
              " 'bringing',\n",
              " 'choking',\n",
              " 'pieces',\n",
              " 'cupboards',\n",
              " 'rock',\n",
              " 'future',\n",
              " 'owner',\n",
              " 'frighten',\n",
              " 'WARRANTY',\n",
              " 'noticing',\n",
              " 'swam',\n",
              " 'general',\n",
              " 'roast',\n",
              " 'stood',\n",
              " 'counting',\n",
              " 'Just',\n",
              " 'seven',\n",
              " 'anything',\n",
              " 'For',\n",
              " 'Oh',\n",
              " 'ledge',\n",
              " 'data',\n",
              " 'cheap',\n",
              " 'catch',\n",
              " 'supple',\n",
              " 'affectionately',\n",
              " 'sage',\n",
              " 'bottle',\n",
              " 'looking',\n",
              " 'identification',\n",
              " 'flung',\n",
              " 'solicit',\n",
              " 'collection',\n",
              " 'turn',\n",
              " 'locations',\n",
              " 'gained',\n",
              " 'An',\n",
              " 'growls',\n",
              " 'brush',\n",
              " 'reminding',\n",
              " 'format',\n",
              " 'flock',\n",
              " 'sit',\n",
              " 'triumphantly',\n",
              " 'flat',\n",
              " 'wow',\n",
              " 'stays',\n",
              " 'golden',\n",
              " 'backs',\n",
              " 'wish',\n",
              " 'cold',\n",
              " 'Lastly',\n",
              " 'choice',\n",
              " 'cunning',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GfkThRpNUKL"
      },
      "source": [
        "Define a function that takes a word and lists the $n$ most similar words in our corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KT_h-7n50kia"
      },
      "source": [
        "import pandas as pd\n",
        "def spacy_closest(tokens, new_vec, n=10):\n",
        "  # Your code here\n",
        "    d = {'tokens': tokens,}\n",
        "    df = pd.DataFrame(data=d)\n",
        "    df['tokens'] = tokens\n",
        "    df['cos_token'] = [cosine(new_vec, nlp(token_i).vector) for token_i in tokens]\n",
        "    df['abs_cos_token'] = [abs(cos_i) for cos_i in df['cos_token']]\n",
        "    return df.sort_values(by=\"abs_cos_token\",)[:n]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTLEiz9UNjrO"
      },
      "source": [
        "Try to find words similar to some random words, e.g. $good$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1JL2VrF0ltD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "1bfdd29b-d290-4c50-8adb-4a770716741f"
      },
      "source": [
        "spacy_closest(tokens, nlp('good').vector)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in true_divide\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         tokens  cos_token  abs_cos_token\n",
              "1038     DIRECT  -0.000424       0.000424\n",
              "1239       grin  -0.000507       0.000507\n",
              "376         USE   0.000618       0.000618\n",
              "2173       woke   0.000618       0.000618\n",
              "954    WARRANTY  -0.000843       0.000843\n",
              "1535        Has   0.000870       0.000870\n",
              "1911    Zealand  -0.001329       0.001329\n",
              "980   locations  -0.001458       0.001458\n",
              "814       threw   0.001668       0.001668\n",
              "2438        paw   0.002174       0.002174"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-38928b21-2748-46e3-90fe-d2aea91c0b65\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tokens</th>\n",
              "      <th>cos_token</th>\n",
              "      <th>abs_cos_token</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1038</th>\n",
              "      <td>DIRECT</td>\n",
              "      <td>-0.000424</td>\n",
              "      <td>0.000424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1239</th>\n",
              "      <td>grin</td>\n",
              "      <td>-0.000507</td>\n",
              "      <td>0.000507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>376</th>\n",
              "      <td>USE</td>\n",
              "      <td>0.000618</td>\n",
              "      <td>0.000618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2173</th>\n",
              "      <td>woke</td>\n",
              "      <td>0.000618</td>\n",
              "      <td>0.000618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>954</th>\n",
              "      <td>WARRANTY</td>\n",
              "      <td>-0.000843</td>\n",
              "      <td>0.000843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1535</th>\n",
              "      <td>Has</td>\n",
              "      <td>0.000870</td>\n",
              "      <td>0.000870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1911</th>\n",
              "      <td>Zealand</td>\n",
              "      <td>-0.001329</td>\n",
              "      <td>0.001329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>980</th>\n",
              "      <td>locations</td>\n",
              "      <td>-0.001458</td>\n",
              "      <td>0.001458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>814</th>\n",
              "      <td>threw</td>\n",
              "      <td>0.001668</td>\n",
              "      <td>0.001668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2438</th>\n",
              "      <td>paw</td>\n",
              "      <td>0.002174</td>\n",
              "      <td>0.002174</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-38928b21-2748-46e3-90fe-d2aea91c0b65')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-38928b21-2748-46e3-90fe-d2aea91c0b65 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-38928b21-2748-46e3-90fe-d2aea91c0b65');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBZhjqSgNqNd"
      },
      "source": [
        "You can also get creative and search for combinations of words. For example, what is similar to $king - man + woman$? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKI4SrhMN-EV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "82cb9653-b3cf-4b71-99d4-8c0318c6ad29"
      },
      "source": [
        "# Your code here\n",
        "spacy_closest(tokens, nlp('king').vector - nlp('man').vector + nlp('woman').vector)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in true_divide\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       tokens  cos_token  abs_cos_token\n",
              "2089      May   0.000215       0.000215\n",
              "2477   Author   0.000225       0.000225\n",
              "2618     suet  -0.000310       0.000310\n",
              "1995       up   0.000323       0.000323\n",
              "1882     nice   0.000408       0.000408\n",
              "2046   BREACH  -0.000448       0.000448\n",
              "240       Ann   0.000455       0.000455\n",
              "233    toffee   0.000542       0.000542\n",
              "401      lose  -0.000731       0.000731\n",
              "683   nervous  -0.000771       0.000771"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fad080dc-42bc-4ea6-b1af-5dd08bad857e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tokens</th>\n",
              "      <th>cos_token</th>\n",
              "      <th>abs_cos_token</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2089</th>\n",
              "      <td>May</td>\n",
              "      <td>0.000215</td>\n",
              "      <td>0.000215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2477</th>\n",
              "      <td>Author</td>\n",
              "      <td>0.000225</td>\n",
              "      <td>0.000225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2618</th>\n",
              "      <td>suet</td>\n",
              "      <td>-0.000310</td>\n",
              "      <td>0.000310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>up</td>\n",
              "      <td>0.000323</td>\n",
              "      <td>0.000323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1882</th>\n",
              "      <td>nice</td>\n",
              "      <td>0.000408</td>\n",
              "      <td>0.000408</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2046</th>\n",
              "      <td>BREACH</td>\n",
              "      <td>-0.000448</td>\n",
              "      <td>0.000448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>240</th>\n",
              "      <td>Ann</td>\n",
              "      <td>0.000455</td>\n",
              "      <td>0.000455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>233</th>\n",
              "      <td>toffee</td>\n",
              "      <td>0.000542</td>\n",
              "      <td>0.000542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>401</th>\n",
              "      <td>lose</td>\n",
              "      <td>-0.000731</td>\n",
              "      <td>0.000731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>683</th>\n",
              "      <td>nervous</td>\n",
              "      <td>-0.000771</td>\n",
              "      <td>0.000771</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fad080dc-42bc-4ea6-b1af-5dd08bad857e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fad080dc-42bc-4ea6-b1af-5dd08bad857e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fad080dc-42bc-4ea6-b1af-5dd08bad857e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpD73pj8OGGt"
      },
      "source": [
        "## **Sentence vectors**\n",
        "\n",
        "We can also construct a vector representation for the whole sentence. For example, we can define it as an *average* of the   vectors representing the words in it.\n",
        "\n",
        "Let's take a random sentence *My favorite food is strawberry ice cream* and construct its vector representation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5xr_3MkEPeM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb37a9ce-1535-4b7f-bec1-ee7d4f27ab3b"
      },
      "source": [
        "sent = nlp('My favorite food is strawberry ice cream.')\n",
        "np.sum(sent[:-1].vector)/(len(sent) - 1)\n",
        "\n",
        "# Your code here\n",
        "# sentv ..."
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-6.100927625383649"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMf_OllyOvfX"
      },
      "source": [
        "Let's also extract sentences (as opposed to individual words) from our corpus:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jazUz0WvDsa3"
      },
      "source": [
        "sents = list(doc.sents)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzDdce7xO7QZ"
      },
      "source": [
        "Define a function that takes a random sentence and lists $n$ most similar sentences from our corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQ7pQe8xD1x0"
      },
      "source": [
        "def spacy_closest_sent(sentences, input_vec, n=10):\n",
        "  # Your code here\n",
        "  d = {'sentences': sentences,}\n",
        "  df = pd.DataFrame(data=d)\n",
        "  df['sentences'] = sentences\n",
        "  df['cos_token'] = [cosine(input_vec, nlp(sentence_i).vector) for sentence_i in sentences]\n",
        "  df['abs_cos_token'] = [abs(cos_i) for cos_i in df['cos_token']]\n",
        "  return df.sort_values(by=\"abs_cos_token\",)[:n]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6m06T18PDQ8"
      },
      "source": [
        "Let's try it out!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkDCEWWwEzIc"
      },
      "source": [
        "for s in spacy_closest_sent(sents, sentv, n=10):\n",
        "  print(s)\n",
        "  print('\\n---')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VewB5XqkPLdx"
      },
      "source": [
        "## **References**\n",
        "\n",
        "This notebook is inspired by a [tutorial by Allison Parrish](https://gist.github.com/aparrish/2f562e3737544cf29aaf1af30362f469)."
      ]
    }
  ]
}